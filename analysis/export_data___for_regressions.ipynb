{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd3a456",
   "metadata": {},
   "source": [
    "# Export data to CSVs for regressions\n",
    "\n",
    "## Connect to Postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import os\n",
    "\n",
    "# build URL from the locallyâ€‘forwarded port\n",
    "user     = os.getenv(\"DB_USER\")\n",
    "pw       = os.getenv(\"DB_PASSWORD\")\n",
    "host     = os.getenv(\"DB_HOST\")\n",
    "port     = os.getenv(\"DB_PORT\")\n",
    "db       = os.getenv(\"DB_NAME\")\n",
    "engine   = create_engine(f\"postgresql://{user}:{pw}@{host}:{port}/{db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15395aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilogs = pd.read_sql(\"SELECT * FROM interaction_logs;\", engine)\n",
    "ilogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a780b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys = pd.read_sql(\"SELECT * FROM survey_responses;\", engine)\n",
    "surveys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = pd.read_sql(\"SELECT * FROM text_snapshots;\", engine)\n",
    "snapshots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18450709",
   "metadata": {},
   "source": [
    "## Get list of accepted participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd39ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_list = []\n",
    "\n",
    "with open(\"pid_accepted.txt\", \"r\") as fle:\n",
    "    for line in fle:\n",
    "        pid_list.append(line.strip())\n",
    "        \n",
    "len(pid_list), pid_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64348f2",
   "metadata": {},
   "source": [
    "## Export pre-survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = surveys.loc[\n",
    "    (surveys[\"participant_id\"].isin(pid_list)) &\n",
    "    (surveys[\"survey_type\"] == \"pre\")\n",
    "]\n",
    "\n",
    "filtered = filtered.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "\n",
    "print(len(filtered), len(pid_list))\n",
    "\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def enrich_response(row):\n",
    "    resp = row[\"responses\"]\n",
    "    if isinstance(resp, str):\n",
    "        try:\n",
    "            resp = json.loads(resp)\n",
    "        except:\n",
    "            resp = {}\n",
    "\n",
    "    enriched = {\n",
    "        **resp,  # unpack original keys\n",
    "        \"participant_id\": row[\"participant_id\"],\n",
    "        \"prompt_id\": row[\"prompt_id\"], \n",
    "        \"condition\": row[\"condition\"]\n",
    "    }\n",
    "    return enriched\n",
    "\n",
    "filtered[\"responses_enriched\"] = filtered.apply(enrich_response, axis=1)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = filtered[\"responses_enriched\"].to_list()\n",
    "\n",
    "presurvey = pd.DataFrame(responses)\n",
    "presurvey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "presurvey.to_csv('csv_exports/presurvey.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceda841",
   "metadata": {},
   "source": [
    "## Export post-survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cda19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = surveys.loc[\n",
    "    (surveys[\"participant_id\"].isin(pid_list)) &\n",
    "    (surveys[\"survey_type\"] == \"post\")\n",
    "]\n",
    "\n",
    "filtered = filtered.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "\n",
    "print(len(filtered), len(pid_list))\n",
    "\n",
    "filtered[\"responses_enriched\"] = filtered.apply(enrich_response, axis=1)\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7884772",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = filtered[\"responses_enriched\"].to_list()\n",
    "\n",
    "postsurvey = pd.DataFrame(responses)\n",
    "postsurvey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0287a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "postsurvey.to_csv('csv_exports/postsurvey.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b332430",
   "metadata": {},
   "source": [
    "## Export behavioral data\n",
    "\n",
    "- time in each stage\n",
    "- keystrokes in each stage\n",
    "- number of AI support requests\n",
    "- edit distance btwn draft and revision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745e8b7",
   "metadata": {},
   "source": [
    "### Test edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "editdistance.eval('banana', 'bahama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_draft(pid):\n",
    "    filtered = ilogs.loc[ilogs[\"participant_id\"] == pid]\n",
    "    \n",
    "    phrase = \"Please write a complete draft essay based on this outline and prompt\"\n",
    "    matches = filtered[filtered[\"event_data\"].apply(lambda d: isinstance(d, dict) and phrase in d.get(\"prompt\", \"\"))]\n",
    "    \n",
    "    if len(matches) < 1:\n",
    "        print(f\"error [{pid}]: no ai draft found\")\n",
    "        return \"\"\n",
    "    \n",
    "    if len(matches) > 1:\n",
    "        print(f\"warning [{pid}]: more than one ai draft found\")\n",
    "        matches = matches.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "    \n",
    "    return matches.iloc[0][\"event_data\"][\"response\"]\n",
    "\n",
    "def get_essay(pid, stage):\n",
    "    filtered = snapshots.loc[\n",
    "        (snapshots[\"participant_id\"] == pid) & \n",
    "        (snapshots[\"type\"] == \"final\") &\n",
    "        (snapshots[\"stage\"] == stage)\n",
    "    ]\n",
    "    # if condition 3, need to pull draft from api request\n",
    "    if len(filtered) == 0:\n",
    "        condition = surveys.loc[surveys[\"participant_id\"] == pid].iloc[0][\"condition\"]\n",
    "        if condition == \"3\":\n",
    "            return get_ai_draft(pid)\n",
    "        else:\n",
    "            print(f\"error [{pid}]: no final submission [{stage}]\")\n",
    "            return \"error\"\n",
    "    if len(filtered) > 1:\n",
    "        print(f\"warning [{pid}]: more than one final submission [{stage}]\")\n",
    "        filtered = filtered.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "    \n",
    "    return filtered.iloc[0][\"text_content\"]\n",
    "\n",
    "\n",
    "draft = get_essay(pid_list[0], \"draft\")\n",
    "revision = get_essay(pid_list[0], \"revision\")\n",
    "print(\"edit distance:\", editdistance.eval(draft, revision))\n",
    "print(\"------------------\")\n",
    "print(draft)\n",
    "print(\"------------------\")\n",
    "print(revision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f9bc",
   "metadata": {},
   "source": [
    "### Prep functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_keystrokes(pid, stage):\n",
    "    filtered = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) &\n",
    "        (ilogs[\"stage\"].str.lower() == stage)\n",
    "    ]\n",
    "    count = filtered['event_type'].str.contains('keystroke').sum()\n",
    "    return count\n",
    "\n",
    "def get_time_on_task(pid, stage):\n",
    "    # return in minutes\n",
    "    filtered = snapshots.loc[\n",
    "        (snapshots[\"participant_id\"] == pid) & \n",
    "        (snapshots[\"type\"] == \"final\") &\n",
    "        (snapshots[\"stage\"] == stage)\n",
    "    ]\n",
    "    \n",
    "    if len(filtered) > 1:\n",
    "        print(f\"warning [{pid}]: more than one stage [{stage}]\")\n",
    "        \n",
    "    if len(filtered) == 0:\n",
    "        return \"null\"\n",
    "    \n",
    "    return filtered.iloc[0][\"time_from_stage_start\"]/60  \n",
    "\n",
    "def get_keystroke_events(pid, keyword):\n",
    "    filtered = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) & \n",
    "        (ilogs[\"event_type\"].str.contains(keyword))\n",
    "    ]\n",
    "    return len(filtered)\n",
    "\n",
    "def get_api_requests(pid):\n",
    "    filtered = ilogs.loc[ilogs[\"participant_id\"] == pid]\n",
    "    count = filtered['event_type'].str.contains('api_call').sum()\n",
    "    return count\n",
    "\n",
    "def get_edit_distance(pid):\n",
    "    draft = get_essay(pid, \"draft\")\n",
    "    revision = get_essay(pid, \"revision\")\n",
    "    return editdistance.eval(draft, revision)\n",
    "\n",
    "def get_condition(pid):\n",
    "    filtered = surveys.loc[surveys[\"participant_id\"] == pid]\n",
    "    return filtered.iloc[0][\"condition\"]\n",
    "\n",
    "def get_prompt_id(pid):\n",
    "    filtered = surveys.loc[surveys[\"participant_id\"] == pid]\n",
    "    return filtered.iloc[0][\"prompt_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b13f8",
   "metadata": {},
   "source": [
    "### Build new dataframe and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "\n",
    "for pid in pid_list:\n",
    "    k_outline = get_num_keystrokes(pid, \"outline\")\n",
    "    k_draft = get_num_keystrokes(pid, \"draft\")\n",
    "    k_revision = get_num_keystrokes(pid, \"revision\")\n",
    "    k_backspace = get_keystroke_events(pid, \"backspace\")\n",
    "\n",
    "    rows.append({\n",
    "        \"participant_id\": pid,\n",
    "        \"condition\": get_condition(pid),\n",
    "        \"prompt_id\": get_prompt_id(pid),\n",
    "        \"time_on_outline\": get_time_on_task(pid, \"outline\"),\n",
    "        \"time_on_draft\": get_time_on_task(pid, \"draft\"),\n",
    "        \"time_on_revision\": get_time_on_task(pid, \"revision\"),\n",
    "        \"keystrokes_outline\": k_outline,\n",
    "        \"keystrokes_draft\": k_draft,\n",
    "        \"keystrokes_revision\": k_revision,\n",
    "        \"wc_outline\": len(get_essay(pid, \"outline\").split(\" \")),\n",
    "        \"wc_draft\": len(get_essay(pid, \"draft\").split(\" \")),\n",
    "        \"wc_revision\": len(get_essay(pid, \"revision\").split(\" \")),\n",
    "        \"num_paste_events\": get_keystroke_events(pid, \"paste\"),\n",
    "        \"num_backspace_events\": k_backspace,\n",
    "        \"backspace_frac\": k_backspace / (k_outline + k_draft + k_revision),\n",
    "        \"api_requests\": get_api_requests(pid),\n",
    "        \"revision_edit_distance\": get_edit_distance(pid)\n",
    "    })\n",
    "\n",
    "behavioral_df = pd.DataFrame(rows)\n",
    "behavioral_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_df.to_csv('csv_exports/behavioraldata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9f343d",
   "metadata": {},
   "source": [
    "# Export submitted text\n",
    "\n",
    "Note that we're rewrite the get_essay function to return an empty string in the ai draft condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf3bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_draft(pid):\n",
    "    filtered = ilogs.loc[ilogs[\"participant_id\"] == pid]\n",
    "    \n",
    "    phrase = \"Please write a complete draft essay based on this outline and prompt\"\n",
    "    matches = filtered[filtered[\"event_data\"].apply(lambda d: isinstance(d, dict) and phrase in d.get(\"prompt\", \"\"))]\n",
    "    \n",
    "    if len(matches) < 1:\n",
    "        print(f\"error [{pid}]: no ai draft found\")\n",
    "        return \"\"\n",
    "    \n",
    "    if len(matches) > 1:\n",
    "        print(f\"warning [{pid}]: more than one ai draft found\")\n",
    "        matches = matches.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "    \n",
    "    return matches.iloc[0][\"event_data\"][\"response\"]\n",
    "\n",
    "def get_essay(pid, stage):\n",
    "    filtered = snapshots.loc[\n",
    "        (snapshots[\"participant_id\"] == pid) & \n",
    "        (snapshots[\"type\"] == \"final\") &\n",
    "        (snapshots[\"stage\"] == stage)\n",
    "    ]\n",
    "    # if condition 3, need to pull draft from api request\n",
    "    if len(filtered) == 0:\n",
    "        condition = surveys.loc[surveys[\"participant_id\"] == pid].iloc[0][\"condition\"]\n",
    "        if condition == \"3\":\n",
    "            return \"\"\n",
    "        else:\n",
    "            print(f\"error [{pid}]: no final submission [{stage}]\")\n",
    "            return \"error\"\n",
    "    if len(filtered) > 1:\n",
    "        print(f\"warning [{pid}]: more than one final submission [{stage}]\")\n",
    "        filtered = filtered.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "    \n",
    "    return filtered.iloc[0][\"text_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for pid in pid_list:\n",
    "    condition = get_condition(pid)\n",
    "    if condition == \"3\":\n",
    "        human_draft = \"\"\n",
    "        ai_draft = get_ai_draft(pid).replace(\"\\n\", \" \")\n",
    "    else:\n",
    "        human_draft = get_essay(pid, \"draft\").replace(\"\\n\", \" \")\n",
    "        ai_draft = \"\"\n",
    "        \n",
    "    rows.append({\n",
    "        \"participant_id\": pid,\n",
    "        \"condition\": get_condition(pid),\n",
    "        \"prompt_id\": get_prompt_id(pid),\n",
    "        \"outline_text\": get_essay(pid, \"outline\").replace(\"\\n\", \" \"), \n",
    "        \"human_draft_text\": human_draft, \n",
    "        \"ai_draft_text\": ai_draft, \n",
    "        \"final_text\": get_essay(pid, \"revision\").replace(\"\\n\", \" \")\n",
    "    })\n",
    "\n",
    "text_df = pd.DataFrame(rows)\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a92bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.to_csv('csv_exports/textdata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647d8a18",
   "metadata": {},
   "source": [
    "# Export AI support data\n",
    "\n",
    "Note that values go to 0 if there is no AI support for a given condition.\n",
    "\n",
    "- **outline_ideas_shown**: Sum of the number of \"thesis\" suggestions / ideas shown to the participant, counted via api requests. (Note that due to logging errors this is either 0 or 3; we don't know if they requested more than 3.)\n",
    "- **outline_detail_shown**: Sum all times \"generate outline\" is requested.\n",
    "- **outline_ideas_pasted**: Count number of times a paste event was of text that was in the AI response (i.e. an idea /outline from the sidebar).\n",
    "- **outline_characters_inserted**: Number of characters pasted from the subset of paste events above.\n",
    "- **revision_ideas_shown**: Number of revision suggestions shown (typically 1â€“4 suggestions returned per request).\n",
    "- **revision_ideas_applied**: Count number of revision suggestions applied to text by checking final essay for suggested fixes.\n",
    "- **revision_characters_inserted**: Number of characters in final submission that came from suggested fixes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9308de7",
   "metadata": {},
   "source": [
    "## Outline metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8034a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outline_ideas_shown(pid):\n",
    "    # Count ideas shown based on which prompt was used in outline-stage API calls\n",
    "    # note that the \"generate a single idea\" prompt wasn't logged :'(\n",
    "    filtered = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) &\n",
    "        (ilogs[\"stage\"].str.lower() == \"outline\") &\n",
    "        (ilogs[\"event_type\"].str.contains(\"api_call:success\", na=False))\n",
    "    ]\n",
    "    total = 0\n",
    "    for _, row in filtered.iterrows():\n",
    "        prompt = row[\"event_data\"][\"prompt\"]\n",
    "        pl = prompt.lower()\n",
    "        if \"please give me 3 distinct thesis ideas for this essay\" in pl:\n",
    "            total += 3\n",
    "        elif \"generate a single interesting thesis statement\" in pl:\n",
    "            total += 1\n",
    "        elif \"create a very concise outline for\" in pl:\n",
    "            continue\n",
    "        elif \"please write a complete draft essay based on this\" in pl:\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"unrecognized outline prompt for {pid}: {prompt[:100]!r}\")\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_outline_detail_shown(pid):\n",
    "    # Count outline detail requests by checking the prompt used in outline-stage API calls\n",
    "    filtered = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) &\n",
    "        (ilogs[\"stage\"].str.lower() == \"outline\") &\n",
    "        (ilogs[\"event_type\"].str.contains(\"api_call:success\", na=False))\n",
    "    ]\n",
    "    count = 0\n",
    "    for _, row in filtered.iterrows():\n",
    "        prompt = row[\"event_data\"][\"prompt\"]\n",
    "        if \"create a very concise outline for\" in prompt.lower():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def check_if_from_recent_cut_copy(pid, paste_row, pasted_text):\n",
    "    \"\"\"Check if pasted text comes from recent cut or copy events\"\"\"\n",
    "    \n",
    "    # Get cut/copy events from the same stage and participant\n",
    "    cut_copy_events = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) &\n",
    "        (ilogs[\"stage\"].str.lower() == paste_row[\"stage\"]) &\n",
    "        (ilogs[\"event_type\"].isin([\"keystroke:cut\", \"keystroke:copy\"])) &\n",
    "        (ilogs[\"time_from_stage_start\"] <= paste_row[\"time_from_stage_start\"])  # Only events before the paste\n",
    "    ]\n",
    "    \n",
    "    # Check if any cut/copy event contains the pasted text\n",
    "    for _, event_row in cut_copy_events.iterrows():\n",
    "        if \"text\" in event_row[\"event_data\"]:\n",
    "            cut_copy_text = event_row[\"event_data\"][\"text\"]\n",
    "            if pasted_text in cut_copy_text or cut_copy_text in pasted_text:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def get_outline_ideas_pasted(pid):\n",
    "    \"\"\"returns num ideas pasted and total chars pasted\"\"\"\n",
    "    # legacy code below; all pastes are from AI suggestions\n",
    "#     calls = ilogs.loc[\n",
    "#         (ilogs[\"participant_id\"] == pid) &\n",
    "#         (ilogs[\"stage\"].str.lower() == \"outline\") &\n",
    "#         (ilogs[\"event_type\"].str.contains(\"api_call:success\", na=False))\n",
    "#     ]\n",
    "\n",
    "#     responses = []\n",
    "#     for _, row in calls.iterrows():\n",
    "#         resp = row[\"event_data\"][\"response\"]\n",
    "#         responses.append(resp)\n",
    "#     if not responses:\n",
    "#         return 0, 0\n",
    "\n",
    "    pastes = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) &\n",
    "        (ilogs[\"stage\"].str.lower() == \"outline\") &\n",
    "        (ilogs[\"event_type\"] == \"keystroke:paste\")\n",
    "    ]\n",
    "\n",
    "    applied = 0\n",
    "    total_chars = 0\n",
    "    for _, row in pastes.iterrows():\n",
    "        pasted = row[\"event_data\"][\"text\"]\n",
    "        is_from_cut_copy = check_if_from_recent_cut_copy(pid, row, pasted)\n",
    "        # Ignore trivial very short pastes to reduce false positives\n",
    "        if len(pasted.strip()) < 5:\n",
    "            continue\n",
    "        applied += 1\n",
    "        total_chars += len(pasted)\n",
    "        # legacy code below; all pastes are from AI suggestions\n",
    "#         if any(pasted in r for r in responses) or is_from_cut_copy:\n",
    "#             applied += 1\n",
    "#             total_chars += len(pasted)\n",
    "#         else:\n",
    "#             if get_condition(pid) == \"2\":\n",
    "#                 print(f\"\\n\\n***\\n\\npaste event [{pid}]:\", pasted)\n",
    "    return applied, total_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109b27f",
   "metadata": {},
   "source": [
    "## Revision metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51892cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_revision_ideas_shown(pid):\n",
    "    # Sum suggestions returned across tool calls by parsing LLM responses\n",
    "    filtered = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) &\n",
    "        (ilogs[\"stage\"].str.lower() == \"revision\") &\n",
    "        (ilogs[\"event_type\"].str.contains(\"api_call:success\", na=False))\n",
    "    ]\n",
    "    total = 0\n",
    "    for _, row in filtered.iterrows():\n",
    "        resp = row[\"event_data\"][\"response\"]\n",
    "        total += max(0, len(re.split(r\"###\\s*Issue\\s+\\d+\", resp)) - 1)\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_revision_ideas_applied(pid):\n",
    "    # checks for revision ideas that end up in the final essay\n",
    "    filtered = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) &\n",
    "        (ilogs[\"stage\"].str.lower() == \"revision\") &\n",
    "        (ilogs[\"event_type\"].str.contains(\"api_call:success\", na=False))\n",
    "    ]\n",
    "    \n",
    "    if len(filtered) == 0:\n",
    "        return 0, 0 \n",
    "    \n",
    "    final_essay = get_essay(pid, \"revision\")\n",
    "    \n",
    "    applied = 0\n",
    "    total_chars = 0\n",
    "    for _, row in filtered.iterrows():\n",
    "        resp = row[\"event_data\"][\"response\"]\n",
    "        for line in resp.split('\\n'):\n",
    "            if \"Addition text\" in line or \"Fix\" in line:\n",
    "                suggestion = line.split(\":\")[1].strip().strip('\"')\n",
    "                if suggestion in final_essay:\n",
    "                    applied += 1\n",
    "                    total_chars += len(suggestion)\n",
    "    return applied, total_chars\n",
    "\n",
    "# deprecated\n",
    "\n",
    "# def get_revision_ideas_pasted(pid):\n",
    "#     \"\"\"returns num ideas pasted and total chars pasted\"\"\"\n",
    "#     calls = ilogs.loc[\n",
    "#         (ilogs[\"participant_id\"] == pid) &\n",
    "#         (ilogs[\"stage\"].str.lower() == \"revision\") &\n",
    "#         (ilogs[\"event_type\"].str.contains(\"api_call:success\", na=False))\n",
    "#     ]\n",
    "\n",
    "#     responses = []\n",
    "#     for _, row in calls.iterrows():\n",
    "#         resp = row[\"event_data\"][\"response\"]\n",
    "#         responses.append(resp)\n",
    "#     if not responses:\n",
    "#         return 0, 0\n",
    "\n",
    "#     pastes = ilogs.loc[\n",
    "#         (ilogs[\"participant_id\"] == pid) &\n",
    "#         (ilogs[\"stage\"].str.lower() == \"revision\") &\n",
    "#         (ilogs[\"event_type\"] == \"keystroke:paste\")\n",
    "#     ]\n",
    "\n",
    "#     applied = 0\n",
    "#     total_chars = 0\n",
    "#     for _, row in pastes.iterrows():\n",
    "#         pasted = row[\"event_data\"][\"text\"]\n",
    "#         if len(pasted.strip()) < 5:\n",
    "#             continue\n",
    "#         if any(pasted in r for r in responses):\n",
    "#             applied += 1\n",
    "#             total_chars += len(pasted)\n",
    "\n",
    "#     return applied, total_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84388987",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_revision_ideas_shown(\"65cb7b14e78fc98ecd71d8de\")\n",
    "b = get_revision_ideas_applied(\"65cb7b14e78fc98ecd71d8de\")\n",
    "\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406af964",
   "metadata": {},
   "source": [
    "## Build dataframe and save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build AI support dataframe for CSV export\n",
    "rows = []\n",
    "\n",
    "for pid in pid_list:\n",
    "    \n",
    "    condition = get_condition(pid)\n",
    "    \n",
    "    if condition == \"2\":\n",
    "        outline_pasted, outline_chars = get_outline_ideas_pasted(pid)\n",
    "    else:\n",
    "        outline_pasted = 0\n",
    "        outline_chars = 0\n",
    "    \n",
    "    if condition == \"4\":\n",
    "        revision_applied, revision_chars = get_revision_ideas_applied(pid)\n",
    "    else:\n",
    "        revision_applied = 0\n",
    "        revision_chars = 0\n",
    "        \n",
    "    rows.append({\n",
    "        \"participant_id\": pid,\n",
    "        \"condition\": condition,\n",
    "        \"prompt_id\": get_prompt_id(pid),\n",
    "        # Outline\n",
    "        \"outline_ideas_shown\": get_outline_ideas_shown(pid),\n",
    "        \"outline_detail_shown\": get_outline_detail_shown(pid),\n",
    "        \"outline_ideas_pasted\": outline_pasted,\n",
    "        \"outline_characters_inserted\": outline_chars,\n",
    "        # Revision\n",
    "        \"revision_ideas_shown\": get_revision_ideas_shown(pid),\n",
    "        \"revision_ideas_applied\": revision_applied,\n",
    "        \"revision_characters_inserted_1\": revision_chars,\n",
    "    })\n",
    "\n",
    "ai_support_df = pd.DataFrame(rows)\n",
    "ai_support_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8365219",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "ai_support_df.loc[ai_support_df[\"condition\"] == \"2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_support_df.to_csv('csv_exports/ai_support.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57be7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
