{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd3a456",
   "metadata": {},
   "source": [
    "# Export data to CSVs for regressions\n",
    "\n",
    "## Connect to Postgres database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c4803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import os\n",
    "\n",
    "# build URL from the locallyâ€‘forwarded port\n",
    "user     = os.getenv(\"DB_USER\")\n",
    "pw       = os.getenv(\"DB_PASSWORD\")\n",
    "host     = os.getenv(\"DB_HOST\")\n",
    "port     = os.getenv(\"DB_PORT\")\n",
    "db       = os.getenv(\"DB_NAME\")\n",
    "engine   = create_engine(f\"postgresql://{user}:{pw}@{host}:{port}/{db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15395aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ilogs = pd.read_sql(\"SELECT * FROM interaction_logs;\", engine)\n",
    "ilogs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a780b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "surveys = pd.read_sql(\"SELECT * FROM survey_responses;\", engine)\n",
    "surveys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d2f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = pd.read_sql(\"SELECT * FROM text_snapshots;\", engine)\n",
    "snapshots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18450709",
   "metadata": {},
   "source": [
    "## Get list of accepted participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd39ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_list = []\n",
    "\n",
    "with open(\"pid_accepted.txt\", \"r\") as fle:\n",
    "    for line in fle:\n",
    "        pid_list.append(line.strip())\n",
    "        \n",
    "len(pid_list), pid_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64348f2",
   "metadata": {},
   "source": [
    "## Export pre-survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f68383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = surveys.loc[\n",
    "    (surveys[\"participant_id\"].isin(pid_list)) &\n",
    "    (surveys[\"survey_type\"] == \"pre\")\n",
    "]\n",
    "\n",
    "filtered = filtered.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "\n",
    "print(len(filtered), len(pid_list))\n",
    "\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a74b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def enrich_response(row):\n",
    "    resp = row[\"responses\"]\n",
    "    if isinstance(resp, str):\n",
    "        try:\n",
    "            resp = json.loads(resp)\n",
    "        except:\n",
    "            resp = {}\n",
    "\n",
    "    enriched = {\n",
    "        **resp,  # unpack original keys\n",
    "        \"participant_id\": row[\"participant_id\"],\n",
    "        \"prompt_id\": row[\"prompt_id\"], \n",
    "        \"condition\": row[\"condition\"]\n",
    "    }\n",
    "    return enriched\n",
    "\n",
    "filtered[\"responses_enriched\"] = filtered.apply(enrich_response, axis=1)\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976a4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = filtered[\"responses_enriched\"].to_list()\n",
    "\n",
    "presurvey = pd.DataFrame(responses)\n",
    "presurvey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e96e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "presurvey.to_csv('csv_exports/presurvey.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ceda841",
   "metadata": {},
   "source": [
    "## Export post-survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cda19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = surveys.loc[\n",
    "    (surveys[\"participant_id\"].isin(pid_list)) &\n",
    "    (surveys[\"survey_type\"] == \"post\")\n",
    "]\n",
    "\n",
    "filtered = filtered.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "\n",
    "print(len(filtered), len(pid_list))\n",
    "\n",
    "filtered[\"responses_enriched\"] = filtered.apply(enrich_response, axis=1)\n",
    "filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7884772",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = filtered[\"responses_enriched\"].to_list()\n",
    "\n",
    "postsurvey = pd.DataFrame(responses)\n",
    "postsurvey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0287a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "postsurvey.to_csv('csv_exports/postsurvey.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b332430",
   "metadata": {},
   "source": [
    "## Export behavioral data\n",
    "\n",
    "- time in each stage\n",
    "- keystrokes in each stage\n",
    "- number of AI support requests\n",
    "- edit distance btwn draft and revision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c745e8b7",
   "metadata": {},
   "source": [
    "### Test edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "editdistance.eval('banana', 'bahama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8571a0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ai_draft(pid):\n",
    "    filtered = ilogs.loc[ilogs[\"participant_id\"] == pid]\n",
    "    \n",
    "    phrase = \"Please write a complete draft essay based on this outline and prompt\"\n",
    "    matches = filtered[filtered[\"event_data\"].apply(lambda d: isinstance(d, dict) and phrase in d.get(\"prompt\", \"\"))]\n",
    "    \n",
    "    if len(matches) < 1:\n",
    "        print(f\"error [{pid}]: no ai draft found\")\n",
    "        return \"null\"\n",
    "    \n",
    "    if len(matches) > 1:\n",
    "        print(f\"warning [{pid}]: more than one ai draft found\")\n",
    "        matches = matches.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "    \n",
    "    return matches.iloc[0][\"event_data\"][\"response\"]\n",
    "\n",
    "def get_essay(pid, stage):\n",
    "    filtered = snapshots.loc[\n",
    "        (snapshots[\"participant_id\"] == pid) & \n",
    "        (snapshots[\"type\"] == \"final\") &\n",
    "        (snapshots[\"stage\"] == stage)\n",
    "    ]\n",
    "    # if condition 3, need to pull draft from api request\n",
    "    if len(filtered) == 0:\n",
    "        condition = surveys.loc[surveys[\"participant_id\"] == pid].iloc[0][\"condition\"]\n",
    "        if condition == \"3\":\n",
    "            return get_ai_draft(pid)\n",
    "        else:\n",
    "            print(f\"error [{pid}]: no final submission [{stage}]\")\n",
    "            return \"error\"\n",
    "    if len(filtered) > 1:\n",
    "        print(f\"warning [{pid}]: more than one final submission [{stage}]\")\n",
    "        filtered = filtered.drop_duplicates(subset=\"participant_id\", keep=\"last\")\n",
    "    \n",
    "    return filtered.iloc[0][\"text_content\"]\n",
    "\n",
    "\n",
    "draft = get_essay(pid_list[0], \"draft\")\n",
    "revision = get_essay(pid_list[0], \"revision\")\n",
    "print(\"edit distance:\", editdistance.eval(draft, revision))\n",
    "print(\"------------------\")\n",
    "print(draft)\n",
    "print(\"------------------\")\n",
    "print(revision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e5f9bc",
   "metadata": {},
   "source": [
    "### Prep functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a254323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_keystrokes(pid, stage):\n",
    "    filtered = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) &\n",
    "        (ilogs[\"stage\"].str.lower() == stage)\n",
    "    ]\n",
    "    count = filtered['event_type'].str.contains('keystroke').sum()\n",
    "    return count\n",
    "\n",
    "def get_time_on_task(pid, stage):\n",
    "    # return in minutes\n",
    "    filtered = snapshots.loc[\n",
    "        (snapshots[\"participant_id\"] == pid) & \n",
    "        (snapshots[\"type\"] == \"final\") &\n",
    "        (snapshots[\"stage\"] == stage)\n",
    "    ]\n",
    "    \n",
    "    if len(filtered) > 1:\n",
    "        print(f\"warning [{pid}]: more than one stage [{stage}]\")\n",
    "        \n",
    "    if len(filtered) == 0:\n",
    "        return \"null\"\n",
    "    \n",
    "    return filtered.iloc[0][\"time_from_stage_start\"]/60  \n",
    "\n",
    "def get_keystroke_events(pid, keyword):\n",
    "    filtered = ilogs.loc[\n",
    "        (ilogs[\"participant_id\"] == pid) & \n",
    "        (ilogs[\"event_type\"].str.contains(keyword))\n",
    "    ]\n",
    "    return len(filtered)\n",
    "\n",
    "def get_api_requests(pid):\n",
    "    filtered = ilogs.loc[ilogs[\"participant_id\"] == pid]\n",
    "    count = filtered['event_type'].str.contains('api_call').sum()\n",
    "    return count\n",
    "\n",
    "def get_edit_distance(pid):\n",
    "    draft = get_essay(pid, \"draft\")\n",
    "    revision = get_essay(pid, \"revision\")\n",
    "    return editdistance.eval(draft, revision)\n",
    "\n",
    "def get_condition(pid):\n",
    "    filtered = surveys.loc[surveys[\"participant_id\"] == pid]\n",
    "    return filtered.iloc[0][\"condition\"]\n",
    "\n",
    "def get_prompt_id(pid):\n",
    "    filtered = surveys.loc[surveys[\"participant_id\"] == pid]\n",
    "    return filtered.iloc[0][\"prompt_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b13f8",
   "metadata": {},
   "source": [
    "### Build new dataframe and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8fdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "\n",
    "for pid in pid_list:\n",
    "    k_outline = get_num_keystrokes(pid, \"outline\")\n",
    "    k_draft = get_num_keystrokes(pid, \"draft\")\n",
    "    k_revision = get_num_keystrokes(pid, \"revision\")\n",
    "    k_backspace = get_keystroke_events(pid, \"backspace\")\n",
    "\n",
    "    rows.append({\n",
    "        \"participant_id\": pid,\n",
    "        \"condition\": get_condition(pid),\n",
    "        \"prompt_id\": get_prompt_id(pid),\n",
    "        \"time_on_outline\": get_time_on_task(pid, \"outline\"),\n",
    "        \"time_on_draft\": get_time_on_task(pid, \"draft\"),\n",
    "        \"time_on_revision\": get_time_on_task(pid, \"revision\"),\n",
    "        \"keystrokes_outline\": k_outline,\n",
    "        \"keystrokes_draft\": k_draft,\n",
    "        \"keystrokes_revision\": k_revision,\n",
    "        \"wc_outline\": len(get_essay(pid, \"outline\").split(\" \")),\n",
    "        \"wc_draft\": len(get_essay(pid, \"draft\").split(\" \")),\n",
    "        \"wc_revision\": len(get_essay(pid, \"revision\").split(\" \")),\n",
    "        \"num_paste_events\": get_keystroke_events(pid, \"paste\"),\n",
    "        \"num_backspace_events\": k_backspace,\n",
    "        \"backspace_frac\": k_backspace / (k_outline + k_draft + k_revision),\n",
    "        \"api_requests\": get_api_requests(pid),\n",
    "        \"revision_edit_distance\": get_edit_distance(pid)\n",
    "    })\n",
    "\n",
    "behavioral_df = pd.DataFrame(rows)\n",
    "behavioral_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93b2668",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavioral_df.to_csv('csv_exports/behavioraldata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23649ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
